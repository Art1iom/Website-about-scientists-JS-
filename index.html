<!doctype html>
<html>
<head>
<title> Теория информации </title>
<meta charset="utf-8">
<link rel="stylesheet" type="text/css" href="css/stylesheet.css" >
<link rel="stylesheet" type="text/css" href="css/index.css" >
</head>
<body>
<a name="TOP"></a>
<header> Теория информации </header>
<nav>
  <h3> Меню сайта </h3>
  <ul class="topmenu">
    <li><a href="index.html">Теория информации</a></li>
    <li><a href="">Учёные</a>
       <ul class="submenu">
    <li><a href="pages/1.html">Клод Шеннон</a></li>
     <li><a href="pages/2.html">Ральф Винтон Лайон Хартли</a></li>
     </ul>
    </li>
    <li><a href="pages/3.html">Глоссарий</a></li>
  </ul>
</nav>
<div>
<h1>
 Что такое теория информации? 
</h1>
<br>
<br>
<a href="https://youtu.be/qhd-sz-GJeo" target="_blank"> <img class="R" src="pic/Youtube1.jpg" width="400" height="226" title="Видео на тему: Что такое теория информации?"></a>
<hr>

<p class="p"> 
	<dfn> Теория информации </dfn> — раздел прикладной математики, радиотехники (теория обработки сигналов) и информатики, относящийся к измерению количества информации, её свойств и устанавливающий предельные соотношения для систем передачи данных.</p>
			<hr>
			<p></p>
<p>	
<dfn>Информация</dfn> - одно из фундаментадьных понятий современноцй науки наряду с такими понятиями, как "вещество" и "энергия". В разных науках существуют различные формальные подходы к жтому вопросу. В информатеке важными являются два понятиями определения:<p>
<fieldset>
	<ol>
	<li>Согласно <big>Клоду Шеннону</big>, <dfn>информации</dfn> - это снятая область. Неопределённость некоторого события- это количество возможных результатов(исходо) данного события.
<p><mark> Такой подход называют <i>содержательным</i> или <i>вероятностным.</i> Например, если мы подбрасываем верх монету, то она может упасть двумя различными способыми (орлом вверх или решкой вверх). Соответственно, у данного события два возможных исхода. Если же подбрасывать игральный кубик, то исходов уже будет шесть</mark></p>
	</li>
	<li>Согласно <big>Колмагорову</big>, <dfn><b>информация</b></dfn>, содержащаяся в последовательности символов, характеризуется безотносительно к сожержанию представленного ей сообщения минимально возможным количеством знаков, необходимых для кодирования этой последовательности.</li>
	<p><mark>Этот подход называют алфавитным. При этом для кодирования наиболее часто используется двоичный алфавит состоящий из нуля и единицы, это так называемое "двоичное кодирование информации".</mark></p>
</ol>
</fieldset>
<section>
	<p>
	<img class="img" width="400" height="226" src="pic/Мозг.jpg">
	<big><b>Основные свойства информации</b></big> можно описать с помощью математической модели, отражающей многие характерные особенности информационной меры, как она 
обычно понимается на интуитивном уровне.
	<br>	Источник информации и канал связи, по которому передается информация, можно моделировать, используя вероятностные представления. 
	<br>	Энтропия источника информации равна логарифму (эффективного) числа сообщений, которые он порождает. Это – мера сложности описания источника (или, как иногда говорят, мера неопределенности сообщения). Такое понимание энтропии тесно связано с понятием энтропии, используемым в термодинамике,однако, не отвечает на вопрос “сколько информации получено”. </p>
</p>
<p class="p"><b>Eдиницы информации, которые чаще используются на практике</b></p>
<table border="1"  height="130" width="500">
	<tr>
		<td> Название </td>
		<td> Размер </td>
	</tr>
	<tr>
		<td> Байт </td>
		<td> 8 бит </td>
	</tr>
		<tr>
		<td> Килобайт </td>
		<td> 10<sup>3</sup> бит </td>
	</tr>
		<tr>
		<td> Мегабайт </td>
		<td> 10<sup>6</sup> бит </td>
	</tr>
		<tr>
		<td> Гигабайт </td>
		<td> 10<sup>9</sup> бит </td>
	</tr>
		<tr>
		<td> Терабайт </td>
		<td> 10<sup>12</sup> бит </td>
	</tr>
		<tr>
		<td> Кибибайт </td>
		<td> 2<sup>10</sup> бит </td>
	</tr>
		<tr>
		<td> Мебибайт </td>
		<td> 2<sup>10</sup> бит </td>
	</tr>
		<tr>
		<td> Гибибайт </td>
		<td> 2<sup>30</sup> бит </td>
	</tr>
	<tr>
		<td> Тебибайт </td>
		<td> 2<sup>40</sup> бит </td>
	</tr>
</table>
<p><big>В качестве <mark>основной единицы количества информации</mark> принято брать <mark>бит</mark> – <i>от binary digit.</i></big></p>
<p>В вопросе хранения информации, основным показателем является не количество информации, а <dfn>информационный объем</dfn>.
<br>
В отличие от количества информации, информационный объем <b>может быть не минимальным</b>.
<br> В частности, кодирование текстов в различных кодировках далеко<b> не оптимально</b>.</p>
</section>
<footer><a href="#TOP">Наверх</a></footer>
<footer><b> Сайт разработал Глотов А.И.</b></footer>
</div>
</body>
</html>